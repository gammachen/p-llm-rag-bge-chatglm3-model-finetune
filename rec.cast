{"version": 2, "width": 138, "height": 33, "timestamp": 1757052044, "env": {"SHELL": "/bin/zsh", "TERM": "xterm-256color"}}
[1.855056, "o", "\u001b[1m\u001b[7m%\u001b[27m\u001b[1m\u001b[0m                                                                                                                                         \r \r"]
[1.855561, "o", "\r\u001b[0m\u001b[27m\u001b[24m\u001b[J(base) shhaofu@shhaofudeMacBook-Pro p-llm-rag-bge-chatglm3-model-finetune % \u001b[K\u001b[?2004h"]
[3.407569, "o", "python simple-web-service/app.py"]
[3.903838, "o", "\u001b[32Dpwd                             \u001b[29D"]
[4.423082, "o", "\b\b\bpython simple-web-service/app.py"]
[5.117208, "o", "\u001b[?2004l\r\r\n"]
[5.304063, "o", "Traceback (most recent call last):\r\n  File \"/Users/shhaofu/Code/cursor-projects/p-llm-rag-bge-chatglm3-model-finetune/simple-web-service/app.py\", line 4, in <module>\r\n"]
[5.304095, "o", "    from document_loader import load_pdf, load_txt, chunk_text\r\n  File \"/Users/shhaofu/Code/cursor-projects/p-llm-rag-bge-chatglm3-model-finetune/simple-web-service/document_loader.py\", line 1, in <module>\r\n"]
[5.304258, "o", "    import fitz  # PyMuPDF\r\n    ^^^^^^^^^^^\r\nModuleNotFoundError: No module named 'fitz'\r\n"]
[5.324979, "o", "\u001b[1m\u001b[7m%\u001b[27m\u001b[1m\u001b[0m                                                                                                                                         \r \r"]
[5.325005, "o", "\r\u001b[0m\u001b[27m\u001b[24m\u001b[J(base) shhaofu@shhaofudeMacBook-Pro p-llm-rag-bge-chatglm3-model-finetune % \u001b[K\u001b[?2004h"]
[19.283437, "o", "c"]
[19.370653, "o", "\bco"]
[19.466688, "o", "n"]
[19.64754, "o", "d"]
[19.749041, "o", "a"]
[41.196932, "o", " "]
[41.571415, "o", "e"]
[41.747013, "o", "n"]
[41.915887, "o", "v"]
[42.102749, "o", " "]
[42.190252, "o", "l"]
[42.399187, "o", "i"]
[42.480752, "o", "s"]
[42.741363, "o", "t"]
[42.869953, "o", "\u001b[?2004l\r\r\n"]
[43.360477, "o", "\r\n# conda environments:\r\n#\r\n                       /Users/shhaofu/Code/Codes/Stock-Prices-Prediction-using-Keras-LSTM-Model/.conda\r\nbase                 * /opt/anaconda3\r\nMinerU                 /opt/anaconda3/envs/MinerU\r\nadala                  /opt/anaconda3/envs/adala\r\nagentscope             /opt/anaconda3/envs/agentscope\r\naireflow               /opt/anaconda3/envs/aireflow\r\nandroidapp             /opt/anaconda3/envs/androidapp\r\nautogpt                /opt/anaconda3/envs/autogpt\r\nbgechatglm3env         /opt/anaconda3/envs/bgechatglm3env\r\nchroma                 /opt/anaconda3/envs/chroma\r\nclip-interrogator      /opt/anaconda3/envs/clip-interrogator\r\ncontent-detection      /opt/anaconda3/envs/content-detection\r\ncosyvoice              /opt/anaconda3/envs/cosyvoice\r\ncrewai                 /opt/anaconda3/envs/crewai\r\ne-light-movie          /opt/anaconda3/envs/e-light-movie\r\nfaceswap               /opt/anaconda3/envs/faceswap\r\nfor-recomments-movie2   /opt/anaconda3/envs/for-recomments-movie2\r\ngensim              "]
[43.360555, "o", "   /opt/anaconda3/envs/gensim\r\nlanggraph              /opt/anaconda3/envs/langgraph\r\nlightrag               /opt/anaconda3/envs/lightrag\r\nmnist-fashion          /opt/anaconda3/envs/mnist-fashion\r\nmusic                  /opt/anaconda3/envs/music\r\npix2text               /opt/anaconda3/envs/pix2text\r\nqwen-vl                /opt/anaconda3/envs/qwen-vl\r\nqwen2finetunning       /opt/anaconda3/envs/qwen2finetunning\r\nqwen_travel            /opt/anaconda3/envs/qwen_travel\r\nspacyevn               /opt/anaconda3/envs/spacyevn\r\nstargan-v3             /opt/anaconda3/envs/stargan-v3\r\ntext-rec-data-g        /opt/anaconda3/envs/text-rec-data-g\r\ntranslate-env          /opt/anaconda3/envs/translate-env\r\nunsloth                /opt/anaconda3/envs/unsloth\r\nvecal-separate-env-39   /opt/anaconda3/envs/vecal-separate-env-39\r\nvehicledet             /opt/anaconda3/envs/vehicledet\r\nvllm                   /opt/anaconda3/envs/vllm\r\nwebdnn_py37            /opt/anaconda3/envs/webdnn_py37\r\nyolo                   /opt/anaconda3/envs/yolo\r\nyo"]
[43.360677, "o", "u-get                /opt/anaconda3/envs/you-get\r\nyoudubenv              /opt/anaconda3/envs/youdubenv\r\n\r\n"]
[43.406958, "o", "\u001b[1m\u001b[7m%\u001b[27m\u001b[1m\u001b[0m                                                                                                                                         \r \r"]
[43.407047, "o", "\r\u001b[0m\u001b[27m\u001b[24m\u001b[J(base) shhaofu@shhaofudeMacBook-Pro p-llm-rag-bge-chatglm3-model-finetune % \u001b[K\u001b[?2004h"]
[44.060101, "o", "c"]
[44.10766, "o", "\bco"]
[44.204459, "o", "n"]
[44.393443, "o", "d"]
[44.491371, "o", "a"]
[44.68999, "o", " "]
[45.77086, "o", "a"]
[46.236339, "o", "c"]
[46.616258, "o", "t"]
[46.839112, "o", "i"]
[46.980523, "o", "v"]
[47.060927, "o", "a"]
[47.406546, "o", "t"]
[47.46382, "o", "e"]
[47.664575, "o", " "]
[50.700774, "o", "\u001b[7mbgechatglm3env\u001b[27m"]
[51.193686, "o", "\u001b[14D\u001b[27mb\u001b[27mg\u001b[27me\u001b[27mc\u001b[27mh\u001b[27ma\u001b[27mt\u001b[27mg\u001b[27ml\u001b[27mm\u001b[27m3\u001b[27me\u001b[27mn\u001b[27mv\u001b[?2004l\r\r\n"]
[51.503358, "o", "\u001b[1m\u001b[7m%\u001b[27m\u001b[1m\u001b[0m                                                                                                                                         \r \r"]
[51.503396, "o", "\r\u001b[0m\u001b[27m\u001b[24m\u001b[J(bgechatglm3env) shhaofu@shhaofudeMacBook-Pro p-llm-rag-bge-chatglm3-model-finetune % \u001b[K\u001b[?2004h"]
[52.267095, "o", "conda activate bgechatglm3env"]
[52.405771, "o", "\u001b[23Denv list               \u001b[15D"]
[53.343287, "o", "\u001b[14Dpython simple-web-service/app.py"]
[54.298061, "o", "\u001b[?2004l"]
[54.298433, "o", "\r\r\n"]
[57.842024, "o", "2025-09-05 14:01:42.136 \r\nWarning: the config option 'server.enableCORS=false' is not compatible with 'server.enableXsrfProtection=true'.\r\nAs a result, 'server.enableCORS' is being overridden to 'true'.\r\n\r\nMore information:\r\nIn order to protect against CSRF attacks, we send a cookie with each request.\r\nTo do so, we must specify allowable origins, which places a restriction on\r\ncross-origin resource sharing.\r\n\r\nIf cross origin resource sharing is required, please disable server.enableXsrfProtection.\r\n            \r\n"]
[57.842683, "o", "2025-09-05 14:01:42.137 \r\n  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\r\n  command:\r\n\r\n    streamlit run simple-web-service/app.py [ARGUMENTS]\r\n"]
[59.453534, "o", "/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\r\n  warnings.warn(\r\n"]
[67.162578, "o", "Setting eos_token is not supported, use the default one.\r\nSetting pad_token is not supported, use the default one.\r\nSetting unk_token is not supported, use the default one.\r\n"]
[68.895681, "o", "\rDownloading shards:   0%|                                                                                           | 0/7 [00:00<?, ?it/s]"]
[70.20154, "o", "\r\n"]
[70.201747, "o", "\rmodel-00006-of-00007.safetensors:   0%|                                                                       | 0.00/1.93G [00:00<?, ?B/s]\u001b[A"]
[93.613853, "o", "\r\n"]
[93.615312, "o", "\rmodel-00006-of-00007.safetensors:   1%|▎                                                            | 10.5M/1.93G [00:23<1:11:20, 448kB/s]\u001b[A"]
[104.81167, "o", "\r\n"]
[104.812595, "o", "\rmodel-00006-of-00007.safetensors:   1%|▎                                                            | 10.5M/1.93G [00:34<1:11:20, 448kB/s]\u001b[A"]
[135.840616, "o", "\r\n"]
[135.841039, "o", "\rmodel-00006-of-00007.safetensors:   1%|▋                                                            | 21.0M/1.93G [01:05<1:44:28, 304kB/s]\u001b[A"]
[148.927904, "o", "\r\n"]
[148.928126, "o", "\rmodel-00006-of-00007.safetensors:   1%|▋                                                            | 21.0M/1.93G [01:18<1:44:28, 304kB/s]\u001b[A"]
[200.874856, "o", "^C"]
[200.877024, "o", "\rmodel-00006-of-00007.safetensors:   1%|▋                                                            | 21.0M/1.93G [02:10<3:17:59, 160kB/s]\r\n"]
[200.878216, "o", "\rDownloading shards:  71%|███████████████████████████████████████████████████████████▎                       | 5/7 [02:11<00:52, 26.40s/it]\r\n"]
[200.883033, "o", "Traceback (most recent call last):\r\n  File \"/Users/shhaofu/Code/cursor-projects/p-llm-rag-bge-chatglm3-model-finetune/simple-web-service/app.py\", line 90, in <module>\r\n"]
[200.883881, "o", "    main()\r\n"]
[200.884013, "o", "  File \"/Users/shhaofu/Code/cursor-projects/p-llm-rag-bge-chatglm3-model-finetune/simple-web-service/app.py\", line 23, in main\r\n"]
[200.884147, "o", "    embedder, vector_db, rag_engine = init_components()\r\n                                      ^^^^^^^^^^^^^^^^^\r\n  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/site-packages/streamlit/runtime/caching/cache_utils.py\", line 165, in wrapper\r\n"]
[200.884574, "o", "    return cached_func(*args, **kwargs)\r\n"]
[200.884764, "o", "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/site-packages/streamlit/runtime/caching/cache_utils.py\", line 194, in __call__\r\n"]
[200.884919, "o", "    return self._get_or_create_cached_value(args, kwargs)\r\n"]
[200.885061, "o", "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/site-packages/streamlit/runtime/caching/cache_utils.py\", line 221, in _get_or_create_cached_value\r\n"]
[200.885245, "o", "    return self._handle_cache_miss(cache, value_key, func_args, func_kwargs)\r\n"]
[200.885336, "o", "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/site-packages/streamlit/runtime/caching/cache_utils.py\", line 277, in _handle_cache_miss\r\n"]
[200.885449, "o", "    computed_value = self._info.func(*func_args, **func_kwargs)\r\n"]
[200.885531, "o", "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/shhaofu/Code/cursor-projects/p-llm-rag-bge-chatglm3-model-finetune/simple-web-service/app.py\", line 14, in init_components\r\n"]
[200.885602, "o", "    rag_engine = ChatGLM3RAG()\r\n                 ^^^^^^^^^^^^^\r\n"]
[200.885643, "o", "  File \"/Users/shhaofu/Code/cursor-projects/p-llm-rag-bge-chatglm3-model-finetune/simple-web-service/rag_engine.py\", line 9, in __init__\r\n"]
[200.885919, "o", "    self.model = AutoModel.from_pretrained(\r\n"]
[200.885932, "o", "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n"]
[200.88601, "o", "  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py\", line 558, in from_pretrained\r\n"]
[200.886553, "o", "    return model_class.from_pretrained(\r\n"]
[200.886566, "o", "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n"]
[200.886643, "o", "  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 3511, in from_pretrained\r\n"]
[200.888007, "o", "    resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(\r\n"]
[200.888028, "o", "                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n"]
[200.888119, "o", "  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/site-packages/transformers/utils/hub.py\", line 1040, in get_checkpoint_shard_files\r\n"]
[200.889204, "o", "    cached_filename = cached_file(\r\n                      ^^^^^^^^^^^^\r\n"]
[200.88933, "o", "  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/site-packages/transformers/utils/hub.py\", line 399, in cached_file\r\n"]
[200.889517, "o", "    resolved_file = hf_hub_download(\r\n                    ^^^^^^^^^^^^^^^^\r\n  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\r\n"]
[200.890733, "o", "    return fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1010, in hf_hub_download\r\n"]
[200.893649, "o", "    return _hf_hub_download_to_cache_dir(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1171, in _hf_hub_download_to_cache_dir\r\n"]
[200.896178, "o", "    _download_to_tmp_and_move(\r\n  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1738, in _download_to_tmp_and_move\r\n"]
[200.897641, "o", "    http_get(\r\n  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 496, in http_get\r\n"]
[200.898091, "o", "    for chunk in r.iter_content(chunk_size=constants.DOWNLOAD_CHUNK_SIZE):\r\n  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/site-packages/requests/models.py\", line 820, in generate\r\n"]
[200.899165, "o", "    yield from self.raw.stream(chunk_size, decode_content=True)\r\n"]
[200.899201, "o", "  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/site-packages/urllib3/response.py\", line 1091, in stream\r\n"]
[200.900094, "o", "    data = self.read(amt=amt, decode_content=decode_content)\r\n"]
[200.902116, "o", "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/site-packages/urllib3/response.py\", line 980, in read\r\n    data = self._raw_read(amt)\r\n           ^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/site-packages/urllib3/response.py\", line 904, in _raw_read\r\n    data = self._fp_read(amt, read1=read1) if not fp_closed else b\"\"\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/site-packages/urllib3/response.py\", line 887, in _fp_read\r\n    return self._fp.read(amt) if amt is not None else self._fp.read()\r\n           ^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/http/client.py\", line 473, in read\r\n"]
[200.903313, "o", "    s = self.fp.read(amt)\r\n"]
[200.903425, "o", "        ^^^^^^^^^^^^^^^^^\r\n  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/socket.py\", line 718, in readinto\r\n"]
[200.904108, "o", "    return self._sock.recv_into(b)\r\n"]
[200.904161, "o", "           ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/ssl.py\", line 1314, in recv_into\r\n"]
[200.904898, "o", "    return self.read(nbytes, buffer)\r\n"]
[200.905107, "o", "           ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/anaconda3/envs/bgechatglm3env/lib/python3.11/ssl.py\", line 1166, in read\r\n"]
[200.905279, "o", "    return self._sslobj.read(len, buffer)\r\n"]
[200.905389, "o", "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nKeyboardInterrupt\r\n"]
[201.053005, "o", "^C"]
[201.081204, "o", "\r\n"]
[201.081424, "o", "\u001b[1m\u001b[7m%\u001b[27m\u001b[1m\u001b[0m                                                                                                                                         \r \r"]
[201.081538, "o", "\r\u001b[0m\u001b[27m\u001b[24m\u001b[J(bgechatglm3env) shhaofu@shhaofudeMacBook-Pro p-llm-rag-bge-chatglm3-model-finetune % \u001b[K"]
[201.081551, "o", "\u001b[?2004h"]
[201.219581, "o", "\u001b[?2004l\r\r\n"]
[201.219755, "o", "\u001b[1m\u001b[7m%\u001b[27m\u001b[1m\u001b[0m                                                                                                                                         \r \r"]
[201.219806, "o", "\r\u001b[0m\u001b[27m\u001b[24m\u001b[J(bgechatglm3env) shhaofu@shhaofudeMacBook-Pro p-llm-rag-bge-chatglm3-model-finetune % \u001b[K\u001b[?2004h"]
[788.985439, "o", "\u001b[?2004l\r\r\n"]
