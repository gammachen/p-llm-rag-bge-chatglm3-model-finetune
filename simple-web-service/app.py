import streamlit as st
import os
import time
import logging
import psutil
import gc
import numpy as np
from document_loader import load_pdf, load_txt, chunk_text
from embedding_utils import BGEM3Embedder
from vector_db import FaissVectorDB
from rag_engine import ChatGLM3RAG

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('app_debug.log')
    ]
)
logger = logging.getLogger(__name__)

# å†…å­˜ç›‘æ§å·¥å…·
def log_memory_usage(operation=""):
    """è®°å½•å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    process = psutil.Process()
    memory_info = process.memory_info()
    logger.info(f"ğŸ’¾ [{operation}] å†…å­˜ä½¿ç”¨: {memory_info.rss / 1024 / 1024:.2f} MB")
    return memory_info.rss / 1024 / 1024

# åˆå§‹åŒ–å…¨å±€å˜é‡
@st.cache_resource
def init_components():
    logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ–ç³»ç»Ÿ...")
    start_time = time.time()
    
    log_memory_usage("åˆå§‹åŒ–å‰")
    
    embedder = BGEM3Embedder()
    vector_db = FaissVectorDB()
    rag_engine = ChatGLM3RAG()
    
    elapsed_time = time.time() - start_time
    memory_used = log_memory_usage("åˆå§‹åŒ–å")
    
    logger.info(f"âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’ï¼Œå†…å­˜ä½¿ç”¨: {memory_used:.2f}MB")
    return embedder, vector_db, rag_engine

# ä¸»åº”ç”¨
def main():
    st.title("æ™ºèƒ½æ–‡æ¡£é—®ç­”ç³»ç»Ÿ (RAG)")
    st.markdown("ä¸Šä¼ æ–‡æ¡£åï¼Œå³å¯åŸºäºæ–‡æ¡£å†…å®¹è¿›è¡Œé—®ç­”")
    
    # åˆå§‹åŒ–ç»„ä»¶
    embedder, vector_db, rag_engine = init_components()
    
    # æ–‡æ¡£ä¸Šä¼ ä¸å¤„ç†
    with st.sidebar:
        st.header("æ–‡æ¡£ç®¡ç†")
        uploaded_files = st.file_uploader(
            "ä¸Šä¼ PDFæˆ–TXTæ–‡æ¡£",
            type=["pdf", "txt"],
            accept_multiple_files=True
        )
        
        if st.button("å¤„ç†æ–‡æ¡£"):
            if uploaded_files:
                with st.spinner("å¤„ç†æ–‡æ¡£ä¸­..."):
                    total_files = len(uploaded_files)
                    logger.info(f"ğŸ“ å¼€å§‹å¤„ç† {total_files} ä¸ªæ–‡ä»¶")
                    
                    # åˆ›å»ºè¿›åº¦æ¡
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    for idx, file in enumerate(uploaded_files):
                        logger.info(f"ğŸ“„ å¤„ç†æ–‡ä»¶ {idx+1}/{total_files}: {file.name}")
                        file_start_time = time.time()
                        
                        # å†…å­˜ç›‘æ§ - æ–‡ä»¶å¤„ç†å‰
                        mem_before_file = log_memory_usage(f"å¤„ç†æ–‡ä»¶ {file.name} å‰")
                        
                        # ä¿å­˜æ–‡ä»¶
                        file_path = f"data/{file.name}"
                        os.makedirs("data", exist_ok=True)
                        with open(file_path, "wb") as f:
                            f.write(file.getbuffer())
                        logger.info(f"ğŸ’¾ æ–‡ä»¶å·²ä¿å­˜: {file_path}")
                        
                        try:
                            # åŠ è½½æ–‡æ¡£å†…å®¹
                            logger.info("ğŸ“– å¼€å§‹åŠ è½½æ–‡æ¡£å†…å®¹...")
                            load_start = time.time()
                            if file.name.endswith(".pdf"):
                                text = load_pdf(file_path)
                            else:
                                text = load_txt(file_path)
                            load_time = time.time() - load_start
                            logger.info(f"âœ… æ–‡æ¡£åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.2f}ç§’ï¼Œæ–‡æœ¬é•¿åº¦: {len(text)}å­—ç¬¦")
                            
                            # åˆ†å—å¤„ç†
                            logger.info("âœ‚ï¸ å¼€å§‹æ–‡æœ¬åˆ†å—...")
                            chunk_start = time.time()
                            chunks = chunk_text(text, chunk_size=512, overlap=50)
                            chunk_time = time.time() - chunk_start
                            logger.info(f"âœ… åˆ†å—å®Œæˆï¼Œè€—æ—¶: {chunk_time:.2f}ç§’ï¼Œå…±{len(chunks)}ä¸ªå—")
                            
                            # å†…å­˜ç›‘æ§ - åˆ†å—å
                            mem_after_chunk = log_memory_usage(f"åˆ†å—å ({file.name})")
                            
                            # ç”Ÿæˆå‘é‡
                            logger.info("ğŸ§® å¼€å§‹ç”Ÿæˆå‘é‡...")
                            vector_start = time.time()
                            vectors = embedder.embed_texts(chunks)
                            vector_time = time.time() - vector_start
                            logger.info(f"âœ… å‘é‡ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {vector_time:.2f}ç§’ï¼Œå‘é‡å½¢çŠ¶: {np.array(vectors).shape}")
                            
                            # å†…å­˜ç›‘æ§ - å‘é‡ç”Ÿæˆå
                            mem_after_vector = log_memory_usage(f"å‘é‡ç”Ÿæˆå ({file.name})")
                            
                            # æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
                            logger.info("ğŸ’¾ å¼€å§‹æ·»åŠ åˆ°å‘é‡æ•°æ®åº“...")
                            db_start = time.time()
                            metadatas = [{"source": file.name}] * len(chunks)
                            vector_db.add_documents(vectors, chunks, metadatas)
                            db_time = time.time() - db_start
                            logger.info(f"âœ… å‘é‡æ•°æ®åº“æ·»åŠ å®Œæˆï¼Œè€—æ—¶: {db_time:.2f}ç§’")
                            
                            # åƒåœ¾å›æ”¶
                            gc.collect()
                            log_memory_usage(f"åƒåœ¾å›æ”¶å ({file.name})")
                            
                            file_total_time = time.time() - file_start_time
                            logger.info(f"ğŸ‰ æ–‡ä»¶ {file.name} å¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶: {file_total_time:.2f}ç§’")
                            
                        except Exception as e:
                            logger.error(f"âŒ å¤„ç†æ–‡ä»¶ {file.name} æ—¶å‡ºé”™: {e}")
                            raise
                        
                        # è¿›åº¦æ›´æ–°
                        progress_bar.progress((idx + 1) / total_files)
                        status_text.text(f"å¤„ç†å®Œæˆ: {file.name}")
                    
                    # æœ€ç»ˆå†…å­˜ç»Ÿè®¡
                    log_memory_usage("æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆ")
                    logger.info(f"âœ… æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {total_files} ä¸ªæ–‡ä»¶")
                
                st.success(f"æˆåŠŸå¤„ç† {len(uploaded_files)} ä¸ªæ–‡æ¡£!")
            else:
                st.warning("è¯·å…ˆä¸Šä¼ æ–‡æ¡£")
    
    # é—®ç­”ç•Œé¢
    st.header("æ–‡æ¡£é—®ç­”")
    query = st.text_input("è¾“å…¥æ‚¨çš„é—®é¢˜:")
    
    if st.button("æé—®") and query:
        logger.info(f"ğŸ¤” ç”¨æˆ·æé—®: {query}")
        
        with st.spinner("æ€è€ƒä¸­..."):
            # å†…å­˜ç›‘æ§ - æé—®å‰
            mem_before_query = log_memory_usage("æé—®å‰")
            
            # å‘é‡åŒ–é—®é¢˜
            logger.info("ğŸ§® å¼€å§‹å‘é‡åŒ–é—®é¢˜...")
            query_vector = embedder.embed_query(query)
            logger.info("âœ… é—®é¢˜å‘é‡åŒ–å®Œæˆ")
            
            # æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼ˆå‡å°‘æ•°é‡ä»¥æ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦ï¼‰
            logger.info("ğŸ” å¼€å§‹æ£€ç´¢ç›¸å…³æ–‡æ¡£...")
            search_start = time.time()
            context_docs = vector_db.search(query_vector, k=2)  # å‡å°‘åˆ°2ä¸ªæ–‡æ¡£
            search_time = time.time() - search_start
            logger.info(f"ğŸ” æ£€ç´¢å®Œæˆï¼Œè€—æ—¶: {search_time:.2f}ç§’ï¼Œæ‰¾åˆ° {len(context_docs)} ä¸ªç›¸å…³æ–‡æ¡£")
            
            # å†…å­˜ç›‘æ§ - æ£€ç´¢å
            mem_after_search = log_memory_usage("æ£€ç´¢å")
            
            # ç”Ÿæˆå›ç­”
            logger.info("ğŸ¤– å¼€å§‹ç”Ÿæˆå›ç­”...")
            response_start = time.time()
            response, references = rag_engine.generate_response(query, context_docs)
            response_time = time.time() - response_start
            response_length = len(response) if response else 0
            logger.info(f"âœ… å›ç­”ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {response_time:.2f}ç§’ï¼Œé•¿åº¦: {response_length}å­—ç¬¦")
            
            # å†…å­˜ç›‘æ§ - å›ç­”ç”Ÿæˆå
            mem_after_response = log_memory_usage("å›ç­”ç”Ÿæˆå")
            
            # æ˜¾ç¤ºç»“æœ
            st.subheader("å›ç­”:")
            st.write(response)
            
            # æ˜¾ç¤ºå¼•ç”¨
            st.subheader("å‚è€ƒæ¥æº:")
            for ref in references:
                with st.expander(f"æ–‡æ¡£: {ref['source']} (ç›¸å…³åº¦: {ref.get('score', 0):.2f})"):
                    st.write(ref['text'])
            
            # åƒåœ¾å›æ”¶
            gc.collect()
            log_memory_usage("åƒåœ¾å›æ”¶å")

if __name__ == "__main__":
    main()