import streamlit as st
import os
import sys
import time
from pathlib import Path
import logging
from typing import List, Dict, Any

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from ollama_embedder import OllamaEmbedder
from gpt35_turbo_rag import Gpt35TurboRAG
from document_loader import load_pdf, load_txt, chunk_text
from vector_db import FaissVectorDB

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app_debug.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Ollama RAG é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ–session state
if 'initialized' not in st.session_state:
    st.session_state.initialized = False
    st.session_state.vector_db = None
    st.session_state.rag_engine = None
    st.session_state.embedder = None

# ç¼“å­˜åˆå§‹åŒ–å‡½æ•°
@st.cache_resource
def initialize_system():
    """åˆå§‹åŒ–RAGç³»ç»Ÿ"""
    try:
        logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ–Ollama RAGç³»ç»Ÿ...")
        
        # åˆå§‹åŒ–åµŒå…¥å™¨
        embedder = OllamaEmbedder()
        
        # åˆå§‹åŒ–RAGå¼•æ“
        rag_engine = Gpt35TurboRAG()
        
        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        vector_db = FaissVectorDB(
            index_path="vector_store/faiss_index_ollama.bin",
            metadata_path="vector_store/metadata_ollama.pkl"
        )
        
        logger.info("âœ… Ollama RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        return embedder, rag_engine, vector_db
        
    except Exception as e:
        logger.error(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        st.error(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return None, None, None

def process_documents(uploaded_files):
    """å¤„ç†ä¸Šä¼ çš„æ–‡æ¡£"""
    try:
        total_files = len(uploaded_files)
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        all_chunks = []
        all_metadata = []
        
        for idx, uploaded_file in enumerate(uploaded_files):
            progress_bar.progress((idx + 1) / total_files)
            status_text.text(f"æ­£åœ¨å¤„ç†: {uploaded_file.name}")
            
            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            temp_path = f"temp_{uploaded_file.name}"
            with open(temp_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹åŠ è½½æ–‡æ¡£
            if uploaded_file.name.endswith('.pdf'):
                text = load_pdf(temp_path)
            else:
                text = load_txt(temp_path)
            
            if text:
                # æ–‡æœ¬åˆ†å—
                chunks = chunk_text(text, chunk_size=512, overlap=50)
                
                for chunk_idx, chunk in enumerate(chunks):
                    all_chunks.append(chunk)
                    all_metadata.append({
                        'source': uploaded_file.name,
                        'chunk_index': chunk_idx,
                        'total_chunks': len(chunks)
                    })
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.remove(temp_path)
        
        if all_chunks:
            # ç”ŸæˆåµŒå…¥
            status_text.text("æ­£åœ¨ç”ŸæˆåµŒå…¥å‘é‡...")
            embeddings = st.session_state.embedder.embed_documents(all_chunks)
            
            # æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
            st.session_state.vector_db.add_documents(embeddings, all_chunks, all_metadata)
            
            progress_bar.progress(1.0)
            status_text.text("âœ… æ–‡æ¡£å¤„ç†å®Œæˆ")
            
            st.success(f"æˆåŠŸå¤„ç†äº† {len(uploaded_files)} ä¸ªæ–‡æ¡£ï¼Œå…± {len(all_chunks)} ä¸ªæ–‡æœ¬å—")
            
    except Exception as e:
        st.error(f"å¤„ç†æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")
        logger.error(f"æ–‡æ¡£å¤„ç†é”™è¯¯: {e}")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.title("ğŸ¤– Ollama RAGç³»ç»Ÿ")
    st.markdown("---")
    
    # ç³»ç»ŸçŠ¶æ€
    if not st.session_state.initialized:
        with st.spinner("æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿ..."):
            embedder, rag_engine, vector_db = initialize_system()
            if all([embedder, rag_engine, vector_db]):
                st.session_state.embedder = embedder
                st.session_state.rag_engine = rag_engine
                st.session_state.vector_db = vector_db
                st.session_state.initialized = True
                st.success("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            else:
                st.error("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
                st.stop()
    
    # æ–‡æ¡£ä¸Šä¼ åŒºåŸŸ
    st.markdown("### ğŸ“„ æ–‡æ¡£ç®¡ç†")
    uploaded_files = st.file_uploader(
        "ä¸Šä¼ æ–‡æ¡£",
        type=['txt', 'pdf', 'docx', 'md'],
        accept_multiple_files=True,
        key="file_uploader"
    )
    
    if uploaded_files and st.button("ğŸ“¤ å¤„ç†æ–‡æ¡£", key="process_docs"):
        process_documents(uploaded_files)
    
    # ç³»ç»Ÿä¿¡æ¯
    st.markdown("---")
    st.markdown("### â„¹ï¸ ç³»ç»Ÿä¿¡æ¯")
    st.info(f"åµŒå…¥æ¨¡å‹: text-embedding-ada-002:latest")
    st.info(f"LLMæ¨¡å‹: gpt-3.5-turbo:latest")
    
    if st.session_state.vector_db:
        doc_count = len(st.session_state.vector_db.metadata)
        st.info(f"å·²ç´¢å¼•æ–‡æ¡£: {doc_count} æ¡")


def main():
    """ä¸»åº”ç”¨ç•Œé¢"""
    st.title("ğŸ¤– Ollama RAG é—®ç­”ç³»ç»Ÿ")
    st.markdown("åŸºäºOllamaçš„text-embedding-ada-002å’Œgpt-3.5-turboçš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
    
    if not st.session_state.initialized:
        st.warning("è¯·ç­‰å¾…ç³»ç»Ÿåˆå§‹åŒ–...")
        return
    
    # ä¸»è¦åŠŸèƒ½åŒºåŸŸ
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### ğŸ’¬ æ™ºèƒ½é—®ç­”")
        
        # æŸ¥è¯¢è¾“å…¥
        query = st.text_area(
            "è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š",
            placeholder="ä¾‹å¦‚ï¼šå¤©é¾™å…«éƒ¨ä¸­ä¹”å³°çš„èº«ä¸–æ˜¯ä»€ä¹ˆï¼Ÿ",
            height=100,
            key="query_input"
        )
        
        # æœç´¢å‚æ•°
        search_k = st.slider("æ£€ç´¢ç›¸å…³æ–‡æ¡£æ•°é‡", 1, 5, 3)
        
        if st.button("ğŸ” æé—®", key="ask_button") and query.strip():
            with st.spinner("æ­£åœ¨ç”Ÿæˆå›ç­”..."):
                try:
                    # ç”ŸæˆæŸ¥è¯¢åµŒå…¥
                    query_embedding = st.session_state.embedder.embed_query(query)
                    
                    # æ£€ç´¢ç›¸å…³æ–‡æ¡£
                    docs = st.session_state.vector_db.search(
                        query_embedding, k=search_k
                    )
                    
                    if docs:
                        # ç”Ÿæˆå›ç­”
                        answer, references = st.session_state.rag_engine.generate_response(
                            query, docs
                        )
                        
                        # æ˜¾ç¤ºç»“æœ
                        st.markdown("### ğŸ¯ å›ç­”")
                        st.markdown(answer)
                        
                        # æ˜¾ç¤ºå¼•ç”¨
                        st.markdown("### ğŸ“š å‚è€ƒæ–‡æ¡£")
                        for i, ref in enumerate(references, 1):
                            with st.expander(f"ğŸ“„ {ref['source']} - ç‰‡æ®µ {i}"):
                                st.text(ref['text'][:500] + "..." if len(ref['text']) > 500 else ref['text'])
                    else:
                        st.info("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼Œè¯·ä¸Šä¼ æ›´å¤šæ–‡æ¡£")
                        
                except Exception as e:
                    st.error(f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {str(e)}")
                    logger.error(f"é—®ç­”é”™è¯¯: {e}")
    
    with col2:
        st.markdown("### ğŸ“Š ç³»ç»Ÿç»Ÿè®¡")
        
        if st.session_state.vector_db:
            doc_count = len(st.session_state.vector_db.metadata)
            st.metric("å·²ç´¢å¼•æ–‡æ¡£", doc_count)
            
            if doc_count > 0:
                sources = set()
                for meta in st.session_state.vector_db.metadata:
                    sources.add(meta.get('source', 'æœªçŸ¥'))
                st.metric("æ–‡æ¡£æ¥æº", len(sources))
        
        # å¿«é€Ÿæ“ä½œ
        st.markdown("### âš¡ å¿«é€Ÿæ“ä½œ")
        
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ•°æ®åº“", key="clear_db"):
            st.session_state.vector_db.clear()
            st.success("æ•°æ®åº“å·²æ¸…ç©º")
            st.rerun()
        
        if st.button("ğŸ“ˆ æŸ¥çœ‹ç»Ÿè®¡", key="show_stats"):
            if st.session_state.vector_db:
                stats = st.session_state.vector_db.get_stats()
                st.json(stats)

if __name__ == "__main__":
    main()