import faiss
import numpy as np
import os
import pickle
import logging
import time
from datetime import datetime


class FaissVectorDB:
    def __init__(self, index_path="vector_store/faiss_index.bin", metadata_path="vector_store/metadata.pkl"):
        # è®¾ç½®æ—¥å¿—
        self.logger = logging.getLogger(__name__)
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            self.logger.setLevel(logging.INFO)
        
        self.index_path = index_path
        self.metadata_path = metadata_path
        self.index = None
        self.metadata = []
        
        self.logger.info(f"ğŸš€ åˆå§‹åŒ–FaissVectorDB")
        self.logger.info(f"ğŸ“ ç´¢å¼•è·¯å¾„: {index_path}")
        self.logger.info(f"ğŸ“ å…ƒæ•°æ®è·¯å¾„: {metadata_path}")
        
        start_time = time.time()
        
        # åŠ è½½ç°æœ‰ç´¢å¼•æˆ–åˆ›å»ºæ–°ç´¢å¼•
        if os.path.exists(index_path) and os.path.exists(metadata_path):
            self.logger.info("ğŸ“‚ æ£€æµ‹åˆ°ç°æœ‰ç´¢å¼•æ–‡ä»¶ï¼Œå¼€å§‹åŠ è½½...")
            self.load_index()
            self.logger.info(f"âœ… ç´¢å¼•åŠ è½½å®Œæˆï¼Œå…±{len(self.metadata)}æ¡è®°å½•")
        else:
            self.logger.info("ğŸ†• æœªæ£€æµ‹åˆ°ç´¢å¼•æ–‡ä»¶ï¼Œåˆ›å»ºæ–°ç´¢å¼•...")
            self.create_index()
            self.logger.info("âœ… æ–°ç´¢å¼•åˆ›å»ºå®Œæˆ")
            
        elapsed_time = time.time() - start_time
        self.logger.info(f"â±ï¸  åˆå§‹åŒ–è€—æ—¶: {elapsed_time:.2f}ç§’")
    
    def create_index(self, dim=1536):
        """åˆ›å»ºæ–°çš„FAISSç´¢å¼•"""
        start_time = time.time()
        self.logger.info(f"ğŸ”§ å¼€å§‹åˆ›å»ºFAISSç´¢å¼•ï¼Œç»´åº¦: {dim}")
        
        self.index = faiss.IndexFlatIP(dim)  # ä½¿ç”¨å†…ç§¯ç›¸ä¼¼åº¦
        os.makedirs(os.path.dirname(self.index_path), exist_ok=True)
        
        elapsed_time = time.time() - start_time
        self.logger.info(f"âœ… FAISSç´¢å¼•åˆ›å»ºå®Œæˆï¼Œè€—æ—¶: {elapsed_time:.4f}ç§’")
    
    def load_index(self):
        """åŠ è½½ç°æœ‰ç´¢å¼•"""
        start_time = time.time()
        self.logger.info("ğŸ“¥ å¼€å§‹åŠ è½½FAISSç´¢å¼•...")
        
        try:
            self.index = faiss.read_index(self.index_path)
            self.logger.info(f"ğŸ“Š ç´¢å¼•ç»´åº¦: {self.index.d}")
            self.logger.info(f"ğŸ“ˆ ç´¢å¼•ä¸­å‘é‡æ•°é‡: {self.index.ntotal}")
            
            with open(self.metadata_path, "rb") as f:
                self.metadata = pickle.load(f)
                
            elapsed_time = time.time() - start_time
            self.logger.info(f"âœ… ç´¢å¼•å’Œå…ƒæ•°æ®åŠ è½½å®Œæˆï¼Œè€—æ—¶: {elapsed_time:.4f}ç§’")
            
        except Exception as e:
            self.logger.error(f"âŒ åŠ è½½ç´¢å¼•æ—¶å‡ºé”™: {e}")
            raise
    
    def save_index(self):
        """ä¿å­˜ç´¢å¼•åˆ°æ–‡ä»¶"""
        start_time = time.time()
        self.logger.info("ğŸ’¾ å¼€å§‹ä¿å­˜ç´¢å¼•åˆ°æ–‡ä»¶...")
        
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(self.index_path), exist_ok=True)
            
            # ä¿å­˜FAISSç´¢å¼•
            faiss.write_index(self.index, self.index_path)
            self.logger.info(f"ğŸ“Š å·²ä¿å­˜ç´¢å¼•ï¼ŒåŒ…å« {self.index.ntotal} ä¸ªå‘é‡")
            
            # ä¿å­˜å…ƒæ•°æ®
            with open(self.metadata_path, "wb") as f:
                pickle.dump(self.metadata, f)
            self.logger.info(f"ğŸ“‹ å·²ä¿å­˜å…ƒæ•°æ®ï¼Œå…± {len(self.metadata)} æ¡è®°å½•")
            
            elapsed_time = time.time() - start_time
            self.logger.info(f"âœ… ç´¢å¼•ä¿å­˜å®Œæˆï¼Œè€—æ—¶: {elapsed_time:.4f}ç§’")
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜ç´¢å¼•æ—¶å‡ºé”™: {e}")
            raise
    
    def add_documents(self, vectors, documents, metadatas):
        """æ·»åŠ æ–‡æ¡£å‘é‡åˆ°ç´¢å¼•"""
        start_time = time.time()
        self.logger.info(f"ğŸ“¥ å¼€å§‹æ·»åŠ æ–‡æ¡£åˆ°ç´¢å¼•...")
        
        try:
            vectors = np.array(vectors).astype('float32')
            original_count = self.index.ntotal
            
            # æ£€æŸ¥ç»´åº¦å¹¶é‡æ–°åˆ›å»ºç´¢å¼•ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if self.index.ntotal == 0 and len(vectors) > 0:
                vector_dim = vectors.shape[1]
                if vector_dim != self.index.d:
                    self.logger.info(f"ğŸ”„ æ£€æµ‹åˆ°ç»´åº¦å˜åŒ–ï¼Œé‡æ–°åˆ›å»ºç´¢å¼•: {self.index.d} -> {vector_dim}")
                    self.create_index(dim=vector_dim)
            
            self.logger.info(f"ğŸ“Š åŸå§‹å‘é‡æ•°é‡: {original_count}")
            self.logger.info(f"ğŸ“Š å¾…æ·»åŠ å‘é‡æ•°é‡: {len(vectors)}")
            self.logger.info(f"ğŸ“Š å‘é‡ç»´åº¦: {vectors.shape[1]}")
            
            # æ·»åŠ å‘é‡åˆ°ç´¢å¼•
            self.index.add(vectors)
            added_count = self.index.ntotal - original_count
            self.logger.info(f"âœ… æˆåŠŸæ·»åŠ  {added_count} ä¸ªå‘é‡")
            
            # æ›´æ–°å…ƒæ•°æ®
            start_idx = len(self.metadata)
            self.logger.info(f"ğŸ“ æ›´æ–°å…ƒæ•°æ®ï¼Œèµ·å§‹ID: {start_idx}")
            
            for i, (doc, meta) in enumerate(zip(documents, metadatas)):
                doc_preview = doc[:100] + "..." if len(doc) > 100 else doc
                self.logger.debug(f"ğŸ“„ æ·»åŠ æ–‡æ¡£ {start_idx + i}: {doc_preview}")
                
                self.metadata.append({
                    "id": start_idx + i,
                    "document": doc,
                    "metadata": meta
                })
            
            # ä¿å­˜ç´¢å¼•
            self.save_index()
            
            elapsed_time = time.time() - start_time
            self.logger.info(f"âœ… æ–‡æ¡£æ·»åŠ å®Œæˆï¼Œæ€»è€—æ—¶: {elapsed_time:.4f}ç§’")
            
        except Exception as e:
            self.logger.error(f"âŒ æ·»åŠ æ–‡æ¡£æ—¶å‡ºé”™: {e}")
            raise
    
    def search(self, query_vector, k=5):
        """ç›¸ä¼¼æ€§æœç´¢"""
        start_time = time.time()
        self.logger.info(f"ğŸ” å¼€å§‹ç›¸ä¼¼æ€§æœç´¢ï¼Œk={k}")
        
        try:
            query_vector = np.array([query_vector]).astype('float32')
            
            if self.index.ntotal == 0:
                self.logger.warning("âš ï¸  ç´¢å¼•ä¸ºç©ºï¼Œæ— æœç´¢ç»“æœ")
                return []
            
            self.logger.info(f"ğŸ“Š ç´¢å¼•ä¸­æ€»å‘é‡æ•°: {self.index.ntotal}")
            
            # æ‰§è¡Œæœç´¢
            distances, indices = self.index.search(query_vector, min(k, self.index.ntotal))
            
            # è·å–ç›¸å…³æ–‡æ¡£å’Œå…ƒæ•°æ®
            results = []
            self.logger.info("ğŸ“‹ æœç´¢ç»“æœ:")
            
            for i, (idx, dist) in enumerate(zip(indices[0], distances[0])):
                if idx >= 0 and idx < len(self.metadata):
                    result = {
                        **self.metadata[idx],
                        "score": float(dist)
                    }
                    results.append(result)
                    
                    doc_preview = result["document"][:50] + "..." if len(result["document"]) > 50 else result["document"]
                    self.logger.info(f"   {i+1}. ID={idx}, åˆ†æ•°={dist:.4f}, å†…å®¹={doc_preview}")
            
            elapsed_time = time.time() - start_time
            self.logger.info(f"âœ… æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(results)} ä¸ªç»“æœï¼Œè€—æ—¶: {elapsed_time:.4f}ç§’")
            
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ æœç´¢æ—¶å‡ºé”™: {e}")
            raise
    
    def clear(self):
        """æ¸…ç©ºæ•°æ®åº“ï¼Œåˆ é™¤æ‰€æœ‰å‘é‡å’Œå…ƒæ•°æ®"""
        self.logger.info("ğŸ—‘ï¸ å¼€å§‹æ¸…ç©ºæ•°æ®åº“...")
        
        try:
            # é‡æ–°åˆ›å»ºç©ºç´¢å¼•
            if self.index:
                dim = self.index.d
                self.create_index(dim=dim)
            else:
                self.create_index()
            
            # æ¸…ç©ºå…ƒæ•°æ®
            self.metadata = []
            
            # åˆ é™¤ç´¢å¼•æ–‡ä»¶
            if os.path.exists(self.index_path):
                os.remove(self.index_path)
                self.logger.info(f"âœ… å·²åˆ é™¤ç´¢å¼•æ–‡ä»¶: {self.index_path}")
            
            if os.path.exists(self.metadata_path):
                os.remove(self.metadata_path)
                self.logger.info(f"âœ… å·²åˆ é™¤å…ƒæ•°æ®æ–‡ä»¶: {self.metadata_path}")
            
            self.logger.info("âœ… æ•°æ®åº“å·²æ¸…ç©º")
            
        except Exception as e:
            self.logger.error(f"âŒ æ¸…ç©ºæ•°æ®åº“æ—¶å‡ºé”™: {e}")
            raise

    def get_stats(self):
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "total_vectors": self.index.ntotal if self.index else 0,
            "total_documents": len(self.metadata),
            "index_path": self.index_path,
            "metadata_path": self.metadata_path,
            "index_exists": os.path.exists(self.index_path),
            "metadata_exists": os.path.exists(self.metadata_path)
        }
        
        self.logger.info("ğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯:")
        for key, value in stats.items():
            self.logger.info(f"   {key}: {value}")
        
        return stats